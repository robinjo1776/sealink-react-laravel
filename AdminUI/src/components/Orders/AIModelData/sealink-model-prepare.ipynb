{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell Inspiron 5559\\AppData\\Local\\Temp\\ipykernel_7308\\2461285878.py:9: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  'created_at': pd.date_range(start='2024-01-01', periods=100, freq='H'),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['scaler.joblib']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from joblib import dump\n",
    "\n",
    "# Sample training data\n",
    "data = pd.DataFrame({\n",
    "    'created_at': pd.date_range(start='2024-01-01', periods=100, freq='H'),\n",
    "    'status': ['shipped'] * 50 + ['pending'] * 50\n",
    "})\n",
    "\n",
    "data['status_encoded'] = pd.factorize(data['status'])[0]\n",
    "data['year'] = data['created_at'].dt.year\n",
    "data['month'] = data['created_at'].dt.month\n",
    "data['day_of_week'] = data['created_at'].dt.dayofweek\n",
    "data['hour'] = data['created_at'].dt.hour\n",
    "data['day'] = data['created_at'].dt.day\n",
    "data['timestamp'] = data['created_at'].astype(int) / 10**9\n",
    "\n",
    "# Features and labels\n",
    "X = data[['timestamp', 'status_encoded', 'year', 'month', 'day_of_week', 'hour', 'day']]\n",
    "y = data['status_encoded']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Train logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Save the model and scaler\n",
    "dump(model, 'logistic_regression_model.joblib')\n",
    "dump(scaler, 'scaler.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, 'logistic_regression_model.joblib')\n",
    "\n",
    "# To load it later\n",
    "model = joblib.load('logistic_regression_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution Before Balancing:\n",
      "status_encoded\n",
      "1    1288\n",
      "2    1265\n",
      "0    1256\n",
      "3    1191\n",
      "Name: count, dtype: int64\n",
      "Class Distribution After Resampling (RandomOverSampler):\n",
      "status_encoded\n",
      "0    1288\n",
      "1    1288\n",
      "2    1288\n",
      "3    1288\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Model Accuracy: 1.0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       258\n",
      "           1       1.00      1.00      1.00       257\n",
      "           2       1.00      1.00      1.00       258\n",
      "           3       1.00      1.00      1.00       258\n",
      "\n",
      "    accuracy                           1.00      1031\n",
      "   macro avg       1.00      1.00      1.00      1031\n",
      "weighted avg       1.00      1.00      1.00      1031\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[258   0   0   0]\n",
      " [  0 257   0   0]\n",
      " [  0   0 258   0]\n",
      " [  0   0   0 258]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check if 'inference.py' exists in the current directory\n",
    "if os.path.isfile('inference.py'):\n",
    "    print(\"inference.py exists!\")\n",
    "else:\n",
    "    print(\"inference.py does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_df = pd.read_csv('customers.csv')\n",
    "print(customers_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "# Load data from S3\n",
    "s3_client = boto3.client('s3')\n",
    "bucket_name = 'logistics-data-sealink'  \n",
    "file_name = 'dashboard-data/orders.csv' \n",
    "\n",
    "# Download the file from S3\n",
    "s3_client.download_file(bucket_name, file_name, 'orders.csv')\n",
    "\n",
    "# Load CSV into pandas dataframe\n",
    "df = pd.read_csv('orders.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# S3 setup\n",
    "bucket_name = \"logistics-data-sealink\"\n",
    "model_key = \"logistic_regression_model.joblib\"  # Just the key/path inside the bucket, not the full s3 URL\n",
    "local_model_path = \"/tmp/logistic_regression_model.joblib\"  # Local path in the SageMaker environment\n",
    "\n",
    "# Download model from S3\n",
    "s3 = boto3.client('s3')\n",
    "s3.download_file(bucket_name, model_key, local_model_path)\n",
    "\n",
    "# Load the model using joblib\n",
    "model = joblib.load(local_model_path)\n",
    "\n",
    "print(\"Model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,000 customers and 5,000 orders have been generated and saved to 'customers_1000_records.json' and 'orders_5000_records.json'.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the extracted model\n",
    "model = joblib.load('logistic_regression_model.joblib')\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['order_id', 'customer_id', 'order_date', 'delivery_date', 'status',\n",
      "       'total_amount', 'shipping_address', 'billing_address', 'payment_method',\n",
      "       'payment_status', 'created_at', 'updated_at'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(model.__dict__)  # Inspect the model's attributes\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
